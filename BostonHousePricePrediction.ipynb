{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Read Data\r\n",
    "col_names=['CRIM','ZN','INDUS','CHAS','NOX','RM','AGE','DIS','RAD','TAX','PTRATIO','B','LSTAT','MEDV']\r\n",
    "housing=pd.read_csv('housing.csv',names=col_names,header=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#understand dataframe\r\n",
    "housing.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "housing.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Checking null values in dataset\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import seaborn as sns\r\n",
    "#plot heatmap of EDA"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Basically we all have numerical values in which we have discrete and continuous variable."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Discrete features\r\n",
    "#find discrete and continous feature\r\n",
    "discrete_feature = #write your code here\r\n",
    "print(f\"Discrete feature count {len(discrete_feature)}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "housing[discrete_feature].head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Finding the realtionship between sales and discrete variable"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "#plot the relationship\r\n",
    "#write your code here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Continuous features\r\n",
    "continuous_feature=#write your code here\r\n",
    "print(f\"Continuous variable count {len(continuous_feature)}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "housing[continuous_feature].head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plot\r\n",
    "#write your code here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "housing.describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Correlation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#write your code here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corr['MEDV'].sort_values(ascending=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plot\r\n",
    "#write your code here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#remove highly correlated features "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#plot\r\n",
    "#write your code here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "housing.plot(kind=\"scatter\", x=\"RM\", y=\"MEDV\", alpha=0.8)\r\n",
    "## as we can see RMs 5,6,7 having MEDV value is 50 we can remove this outlier "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Outliers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#find outliers\r\n",
    "#write your code here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## applying log transformation\r\n",
    "#write your code here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#after applying log transgormation we can see the boxplot in some of the features outliers are removed\r\n",
    "\r\n",
    "#write your code here\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#find quantile\r\n",
    "#write your code here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## after removing the outlier plot\r\n",
    "#write your code here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "housing.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "housing.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "#### While doing feature engineering first we want to do train test split to avoid data lekage"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#write your code here\r\n",
    "x=\r\n",
    "y="
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "#write your code here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_test.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train.shape, X_test.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train=X_train.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## most of the data is skewed so for that we apply log transformation\r\n",
    "import numpy as np\r\n",
    "num_features=['CRIM','NOX','DIS','TAX','LSTAT','B','RM','PTRATIO','INDUS']\r\n",
    "for feature in num_features:\r\n",
    "#write your code here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import seaborn as sns\r\n",
    "#Using Pearson Correlation\r\n",
    "#write your code here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def correlation(dataset, threshold):\r\n",
    "    col_corr = set()  # Set of all the names of correlated columns\r\n",
    "    corr_matrix = dataset.corr()\r\n",
    "    \r\n",
    "        #write your code here\r\n",
    "    return col_corr"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "corr_features = correlation(X_train, 0.85)\r\n",
    "print(len(set(corr_features)))\r\n",
    "corr_features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "As we can see that RAD and TAX is highly correlated so we can drop any one column."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#drop feature RAD\r\n",
    "#write your code here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Feature Scaling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import StandardScaler\r\n",
    "scaler=StandardScaler()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#write your code here"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train_SC"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train=pd.DataFrame(X_train_SC,columns=X_train.columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Feature Selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import Lasso\r\n",
    "from sklearn.feature_selection import SelectFromModel\r\n",
    "#write your code here # remember to set the seed, the random state in this function\r\n",
    "feature_sel_model.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "selected_feat = X_train.columns[(feature_sel_model.get_support())]\r\n",
    "selected_feat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "Although we can see that all features are important and not a single feature coefficient is shrinks less than or equal to  0.005"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Makining changes in test data applying log and standard scaler"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#### Testing on the test data\r\n",
    "#### applying log on test data\r\n",
    "X_test=X_test.copy()\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "#start num_features with only one feature first, increase and see accuracy \r\n",
    "#num_features=['CRIM','NOX','DIS','TAX','LSTAT','B','RM','PTRATIO','INDUS']\r\n",
    "for feature in num_features:\r\n",
    "    #write your code here\r\n",
    "\r\n",
    "#write your code here #drop feature RAD\r\n",
    "\r\n",
    "#### applying SC on test data\r\n",
    "#write your code here\r\n",
    "X_test=pd.DataFrame(X_test_SC,columns=X_test.columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_test.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_test.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Selecting a desired model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Using Linear Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LinearRegression\r\n",
    "model=#your code\r\n",
    "model.fit(#your code)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Using Metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\r\n",
    "predictions1=model.predict(X_train)\r\n",
    "\r\n",
    "print(f\"R Squared = {r2} \\nMean Squared Error = {mse} \\nMean Absolute Error = {mae} \\nRoot Mean Squared Error = {rmse}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Using Lasso Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import Lasso\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Using Metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Using K Nearest Neighbour"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Using Metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Using Decison Tree Regressor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Overfitting occurs we will do cross validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import cross_val_score\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Using Random Forest Regressor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Using Metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Testing on Test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#KNN model on test data\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Decison tree on test data\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Random Forest tree on test data\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random Forest Regressor is showing high accuracy and less RMSE both on test and train data."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Hyperparameter Tuning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using RandomizedSearchCV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ####Hyperparameters\r\n",
    "# # Number of trees in random forest\r\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\r\n",
    "# # Number of features to consider at every split\r\n",
    "# max_features = ['auto', 'sqrt','log2']\r\n",
    "# # Maximum number of levels in tree\r\n",
    "# max_depth = [int(x) for x in np.linspace(10, 1000,10)]\r\n",
    "# # Minimum number of samples required to split a node\r\n",
    "# min_samples_split = [2, 5, 7, 8, 9, 10, 11, 13]\r\n",
    "# # Minimum number of samples required at each leaf node\r\n",
    "# min_samples_leaf = [1, 2, 4, 6, 8]\r\n",
    "# # Create the random grid\r\n",
    "# random_grid = {'n_estimators': n_estimators,\r\n",
    "#                'max_features': max_features,\r\n",
    "#                'max_depth':max_depth,\r\n",
    "#                'min_samples_split': min_samples_split,\r\n",
    "#                'min_samples_leaf': min_samples_leaf,\r\n",
    "#               }\r\n",
    "# print(random_grid)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\r\n",
    "# from sklearn.ensemble import RandomForestRegressor\r\n",
    "# es=RandomForestRegressor()\r\n",
    "# model=RandomizedSearchCV(estimator=es,param_distributions=random_grid,scoring='neg_mean_squared_error',n_iter=10,cv=10,verbose=2,n_jobs=1,random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model.fit(X_train,y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# p=model.predict(X_test)\r\n",
    "# r2=r2_score(y_test,p)\r\n",
    "# mse=mean_squared_error(y_test,p)\r\n",
    "# mae=mean_absolute_error(y_test,p)\r\n",
    "# rmse=np.sqrt(mse)\r\n",
    "# print(f\"R Squared = {r2} \\nMean Squared Error = {mse} \\nMean Absolute Error = {mae} \\nRoot Mean Squared Error = {rmse}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using GridSearchCV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from sklearn.model_selection import GridSearchCV\r\n",
    "# # Number of trees in random forest\r\n",
    "# n_estimators = [900,1000,1100]\r\n",
    "# # Number of features to consider at every split\r\n",
    "# max_features = ['sqrt']\r\n",
    "# # Maximum number of levels in tree\r\n",
    "# max_depth = [900,1000,1100]\r\n",
    "# # Minimum number of samples required to split a node\r\n",
    "# min_samples_split = [2,3,5]\r\n",
    "# # Minimum number of samples required at each leaf node\r\n",
    "# min_samples_leaf = [1,2,3]\r\n",
    "# # Create the random grid\r\n",
    "# random_grid = {'n_estimators': n_estimators,\r\n",
    "#                'max_features': max_features,\r\n",
    "#                'max_depth':max_depth,\r\n",
    "#                'min_samples_split': min_samples_split,\r\n",
    "#                'min_samples_leaf': min_samples_leaf,\r\n",
    "#               }\r\n",
    "# print(random_grid)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model1=GridSearchCV(estimator=es,param_grid=random_grid,scoring='neg_mean_squared_error',cv=10,verbose=2,n_jobs=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model1.fit(X_train,y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# model1.best_params_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### using best parameters\r\n",
    "model1=RandomForestRegressor(n_estimators=1100,max_depth=900,max_features='sqrt',min_samples_leaf=1,min_samples_split=2)\r\n",
    "model1.fit(X_train,y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Using Metrics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#after hypertuning Random Forest tree on train data\r\n",
    "predictionsRF1=model1.predict(X_train)\r\n",
    "r2=r2_score(y_train,predictionsRF1)\r\n",
    "mse=mean_squared_error(y_train,predictionsRF1)\r\n",
    "mae=mean_absolute_error(y_train,predictionsRF1)\r\n",
    "rmse=np.sqrt(mse)\r\n",
    "print(f\"R Squared = {r2} \\nMean Squared Error = {mse} \\nMean Absolute Error = {mae} \\nRoot Mean Squared Error = {rmse}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#after hypertuning Random Forest tree on test data\r\n",
    "predictionsRF2=model1.predict(X_test)\r\n",
    "r2=r2_score(y_test,predictionsRF2)\r\n",
    "mse=mean_squared_error(y_test,predictionsRF2)\r\n",
    "mae=mean_absolute_error(y_test,predictionsRF2)\r\n",
    "rmse=np.sqrt(mse)\r\n",
    "print(f\"R Squared = {r2} \\nMean Squared Error = {mse} \\nMean Absolute Error = {mae} \\nRoot Mean Squared Error = {rmse}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.distplot(y_test-predictionsRF2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.scatter(y_test,predictionsRF2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.regplot(x=y_test,y=predictionsRF2,scatter=True,marker='*')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pickle\r\n",
    "file=open('RFHouseModel.pkl','wb')\r\n",
    "pickle.dump(model1,file)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pickle.dump(scaler,open('Scaler.pkl','wb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "interpreter": {
   "hash": "a1b4f4b5b59d091f24ed8aad52614a3516ad0de64d607555a43675d2b4fd5eeb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}